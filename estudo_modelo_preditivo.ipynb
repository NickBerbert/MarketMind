{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† MarketMind - Estudo: Modelo Preditivo Temporal para A√ß√µes\n",
    "\n",
    "## üìã Contexto e Problema\n",
    "\n",
    "**Problema Identificado:**\n",
    "- O modelo atual (ensemble de RandomForest, ExtraTrees, Ridge, ElasticNet) apresenta **confian√ßa muito alta** (70-90%)\n",
    "- Modelos tradicionais de ML **n√£o capturam depend√™ncias temporais**\n",
    "- Dados financeiros s√£o **n√£o-estacion√°rios** e com **alta volatilidade**\n",
    "- **Pouco hist√≥rico** dispon√≠vel (3 meses via API)\n",
    "- **Overfitting** √© altamente prov√°vel com valida√ß√£o inadequada\n",
    "\n",
    "**Objetivo:**\n",
    "Desenvolver um modelo que:\n",
    "1. ‚úÖ Capture depend√™ncias temporais (LSTM, GRU, ou Temporal CNN)\n",
    "2. ‚úÖ Apresente m√©tricas **realistas** (confian√ßa moderada/baixa)\n",
    "3. ‚úÖ Funcione com poucos dados (t√©cnicas de regulariza√ß√£o)\n",
    "4. ‚úÖ Seja honesto sobre limita√ß√µes (intervalos de confian√ßa)\n",
    "\n",
    "**Abordagem:**\n",
    "- Walk-forward validation (valida√ß√£o temporal rigorosa)\n",
    "- Ensemble de modelos temporais + tradicionais\n",
    "- Quantifica√ß√£o de incerteza (predi√ß√£o probabil√≠stica)\n",
    "- Compara√ß√£o de m√∫ltiplas arquiteturas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML tradicional\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Bidirectional, Conv1D, MaxPooling1D, Flatten, Input, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Configura√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"‚úÖ TensorFlow vers√£o: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU dispon√≠vel: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fun√ß√µes de Coleta de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"nUUZxG2ZdAWuSkBDhPobC2\"\n",
    "BASE_URL = \"https://brapi.dev/api\"\n",
    "\n",
    "def buscar_dados_acao(ticker, range='6mo', interval='1d'):\n",
    "    \"\"\"\n",
    "    Busca dados hist√≥ricos de uma a√ß√£o\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "        response = requests.get(\n",
    "            f\"{BASE_URL}/quote/{ticker}?range={range}&interval={interval}\",\n",
    "            headers=headers,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None, f\"Erro {response.status_code}\"\n",
    "        \n",
    "        data = response.json()\n",
    "        if 'results' not in data or not data['results']:\n",
    "            return None, f\"Ticker {ticker} n√£o encontrado\"\n",
    "        \n",
    "        hist_data = data['results'][0].get('historicalDataPrice', [])\n",
    "        \n",
    "        if not hist_data:\n",
    "            return None, \"Sem dados hist√≥ricos\"\n",
    "        \n",
    "        hist_list = []\n",
    "        for item in hist_data:\n",
    "            try:\n",
    "                hist_list.append({\n",
    "                    'Data': datetime.fromtimestamp(item['date']),\n",
    "                    'Open': item.get('open', 0),\n",
    "                    'High': item.get('high', 0),\n",
    "                    'Low': item.get('low', 0),\n",
    "                    'Close': item.get('close', 0),\n",
    "                    'Volume': item.get('volume', 0)\n",
    "                })\n",
    "            except (KeyError, ValueError):\n",
    "                continue\n",
    "        \n",
    "        if hist_list:\n",
    "            df = pd.DataFrame(hist_list).set_index('Data').sort_index()\n",
    "            return df, None\n",
    "        \n",
    "        return None, \"Dados inv√°lidos\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Erro: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de coleta prontas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engenharia de Features (Igual ao App)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_rsi(prices, period=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return (100 - (100 / (1 + rs))).fillna(50)\n",
    "\n",
    "def calcular_macd(prices, fast=12, slow=26):\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    return (ema_fast - ema_slow).fillna(0)\n",
    "\n",
    "def calcular_bollinger_bands(prices, window=20, std_dev=2):\n",
    "    ma = prices.rolling(window=window).mean()\n",
    "    std = prices.rolling(window=window).std()\n",
    "    upper = ma + (std * std_dev)\n",
    "    lower = ma - (std * std_dev)\n",
    "    return upper.fillna(prices), lower.fillna(prices)\n",
    "\n",
    "def adicionar_features_tecnicas(df):\n",
    "    \"\"\"\n",
    "    Adiciona as mesmas 15 features usadas no app.py\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # M√©dias m√≥veis\n",
    "    df['SMA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['EMA_12'] = df['Close'].ewm(span=12).mean()\n",
    "    df['EMA_26'] = df['Close'].ewm(span=26).mean()\n",
    "    \n",
    "    # Indicadores\n",
    "    df['RSI'] = calcular_rsi(df['Close'], period=14)\n",
    "    df['MACD'] = calcular_macd(df['Close'])\n",
    "    df['BB_upper'], df['BB_lower'] = calcular_bollinger_bands(df['Close'])\n",
    "    df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / df['Close']\n",
    "    df['BB_position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
    "    \n",
    "    # Retornos\n",
    "    df['Return_1d'] = df['Close'].pct_change()\n",
    "    df['Return_3d'] = df['Close'].pct_change(3)\n",
    "    df['Return_5d'] = df['Close'].pct_change(5)\n",
    "    \n",
    "    # Volatilidade\n",
    "    df['Volatility_10d'] = df['Return_1d'].rolling(window=10).std()\n",
    "    df['Volatility_20d'] = df['Return_1d'].rolling(window=20).std()\n",
    "    \n",
    "    # Volume\n",
    "    df['Volume_SMA_10'] = df['Volume'].rolling(window=10).mean()\n",
    "    df['Volume_ratio'] = df['Volume'] / df['Volume_SMA_10']\n",
    "    \n",
    "    # Tend√™ncia\n",
    "    df['Price_above_SMA20'] = (df['Close'] > df['SMA_20']).astype(int)\n",
    "    df['SMA_trend'] = (df['SMA_5'] > df['SMA_20']).astype(int)\n",
    "    \n",
    "    # MACD signal\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9).mean()\n",
    "    df['MACD_histogram'] = df['MACD'] - df['MACD_signal']\n",
    "    \n",
    "    # Raz√µes\n",
    "    df['High_Low_ratio'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['Open_Close_ratio'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"‚úÖ Features t√©cnicas configuradas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Buscar Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar dados de uma a√ß√£o l√≠quida\n",
    "TICKER = \"PETR4\"  # Altere conforme necess√°rio\n",
    "\n",
    "print(f\"üîç Buscando dados de {TICKER}...\")\n",
    "df_raw, erro = buscar_dados_acao(TICKER, range='6mo', interval='1d')\n",
    "\n",
    "if erro:\n",
    "    print(f\"‚ùå Erro: {erro}\")\n",
    "else:\n",
    "    print(f\"‚úÖ {len(df_raw)} dias de dados coletados\")\n",
    "    \n",
    "    # Adicionar features\n",
    "    df = adicionar_features_tecnicas(df_raw)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    print(f\"‚úÖ {len(df)} dias ap√≥s limpeza\")\n",
    "    print(f\"\\nüìä Per√≠odo: {df.index.min().strftime('%d/%m/%Y')} at√© {df.index.max().strftime('%d/%m/%Y')}\")\n",
    "    \n",
    "    # Visualizar\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(df.index, df['Close'], linewidth=2, color='#00d4ff')\n",
    "    ax.set_title(f'{TICKER} - Dados Coletados', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Data')\n",
    "    ax.set_ylabel('Pre√ßo (R$)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    display(df[['Close', 'Volume', 'RSI', 'MACD', 'Volatility_20d']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An√°lise do Problema Atual\n",
    "\n",
    "### 5.1 Por que o modelo atual tem confian√ßa inflada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç AN√ÅLISE DE PROBLEMAS DO MODELO ATUAL\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ PROBLEMA: Data Leakage na Valida√ß√£o\")\n",
    "print(\"   - Time Series Split usa apenas 3 folds\")\n",
    "print(\"   - Train/test n√£o s√£o completamente separados temporalmente\")\n",
    "print(\"   - Features podem 'vazar' informa√ß√£o do futuro\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ PROBLEMA: Modelos N√£o-Temporais\")\n",
    "print(\"   - RandomForest, Ridge, ElasticNet n√£o capturam ordem temporal\")\n",
    "print(\"   - Tratam cada observa√ß√£o como independente (IID assumption)\")\n",
    "print(\"   - A√ß√µes s√£o s√©ries temporais com autocorrela√ß√£o forte\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ PROBLEMA: C√°lculo de Confian√ßa Ing√™nuo\")\n",
    "print(\"   - confianca = max(0.4, min(0.9, 1.0 - mae * 15))\")\n",
    "print(\"   - Limites arbitr√°rios (40% a 90%)\")\n",
    "print(\"   - N√£o considera incerteza epist√™mica (falta de dados)\")\n",
    "print(\"   - N√£o considera incerteza aleat√≥ria (volatilidade do mercado)\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ PROBLEMA: Poucos Dados\")\n",
    "print(f\"   - Apenas {len(df)} dias (~{len(df)/252:.1f} anos de trading)\")\n",
    "print(\"   - Modelos complexos facilmente overfitam\")\n",
    "print(\"   - N√£o captura diferentes regimes de mercado\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ PROBLEMA: Target Inadequado\")\n",
    "print(\"   - Prev√™ retornos percentuais de 1-5 dias\")\n",
    "print(\"   - Converte para pre√ßos multiplicando retornos sequencialmente\")\n",
    "print(\"   - Acumula erros compostos\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ PROBLEMA: Sem Quantifica√ß√£o de Incerteza\")\n",
    "print(\"   - Previs√£o pontual (single point estimate)\")\n",
    "print(\"   - N√£o fornece intervalos de confian√ßa\")\n",
    "print(\"   - Usu√°rio n√£o sabe o 'range' de possibilidades\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepara√ß√£o de Dados para Modelos Temporais\n",
    "\n",
    "### 6.1 Sequ√™ncias de Janelas Deslizantes (Sliding Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_sequencias_temporais(df, window_size=20, forecast_horizon=5):\n",
    "    \"\"\"\n",
    "    Cria sequ√™ncias temporais para modelos LSTM/GRU\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame com features\n",
    "        window_size: Tamanho da janela de lookback (dias passados)\n",
    "        forecast_horizon: Dias para frente a prever\n",
    "    \n",
    "    Returns:\n",
    "        X: Array 3D (samples, timesteps, features)\n",
    "        y: Array 2D (samples, forecast_horizon)\n",
    "        feature_names: Lista de nomes das features\n",
    "        dates: Datas correspondentes\n",
    "    \"\"\"\n",
    "    # Features a usar\n",
    "    feature_cols = [\n",
    "        'Return_1d', 'Return_3d', 'Return_5d',\n",
    "        'RSI', 'MACD', 'MACD_histogram',\n",
    "        'BB_width', 'BB_position',\n",
    "        'Volatility_10d', 'Volatility_20d',\n",
    "        'Volume_ratio', 'High_Low_ratio', 'Open_Close_ratio',\n",
    "        'Price_above_SMA20', 'SMA_trend'\n",
    "    ]\n",
    "    \n",
    "    # Normalizar features (importante para redes neurais)\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(df[feature_cols].values)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    dates = []\n",
    "    \n",
    "    for i in range(window_size, len(df) - forecast_horizon):\n",
    "        # Janela de features (window_size dias passados)\n",
    "        X.append(features_scaled[i-window_size:i])\n",
    "        \n",
    "        # Target: retornos dos pr√≥ximos forecast_horizon dias\n",
    "        current_price = df['Close'].iloc[i]\n",
    "        future_returns = []\n",
    "        \n",
    "        for j in range(1, forecast_horizon + 1):\n",
    "            future_price = df['Close'].iloc[i + j]\n",
    "            ret = (future_price - current_price) / current_price\n",
    "            future_returns.append(ret)\n",
    "        \n",
    "        y.append(future_returns)\n",
    "        dates.append(df.index[i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y, feature_cols, dates, scaler\n",
    "\n",
    "# Criar sequ√™ncias\n",
    "WINDOW_SIZE = 20  # 20 dias de lookback (~1 m√™s de trading)\n",
    "FORECAST_HORIZON = 5  # Prever 5 dias para frente\n",
    "\n",
    "X, y, feature_names, dates, scaler = criar_sequencias_temporais(\n",
    "    df, \n",
    "    window_size=WINDOW_SIZE, \n",
    "    forecast_horizon=FORECAST_HORIZON\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Sequ√™ncias criadas\")\n",
    "print(f\"   Shape de X: {X.shape} (samples, timesteps, features)\")\n",
    "print(f\"   Shape de y: {y.shape} (samples, forecast_days)\")\n",
    "print(f\"   Features: {len(feature_names)}\")\n",
    "print(f\"   Samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Walk-Forward Split (Valida√ß√£o Temporal Rigorosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_split(X, y, n_splits=5, test_size=10):\n",
    "    \"\"\"\n",
    "    Walk-forward validation: treina em dados passados, testa em dados futuros\n",
    "    \n",
    "    Exemplo com 100 amostras, n_splits=5, test_size=10:\n",
    "    Split 1: Train [0:50],  Test [50:60]\n",
    "    Split 2: Train [0:60],  Test [60:70]\n",
    "    Split 3: Train [0:70],  Test [70:80]\n",
    "    Split 4: Train [0:80],  Test [80:90]\n",
    "    Split 5: Train [0:90],  Test [90:100]\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    splits = []\n",
    "    \n",
    "    # Tamanho inicial de treino (pelo menos 50% dos dados)\n",
    "    initial_train_size = n_samples - (n_splits * test_size)\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = initial_train_size + (i * test_size)\n",
    "        test_start = train_end\n",
    "        test_end = test_start + test_size\n",
    "        \n",
    "        if test_end > n_samples:\n",
    "            test_end = n_samples\n",
    "        \n",
    "        train_idx = list(range(0, train_end))\n",
    "        test_idx = list(range(test_start, test_end))\n",
    "        \n",
    "        if len(test_idx) >= 5:  # M√≠nimo de amostras para teste\n",
    "            splits.append((train_idx, test_idx))\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Criar splits\n",
    "splits = walk_forward_split(X, y, n_splits=5, test_size=10)\n",
    "\n",
    "print(f\"‚úÖ {len(splits)} splits criados (Walk-Forward Validation)\")\n",
    "print(\"\\nDetalhes dos splits:\")\n",
    "for i, (train_idx, test_idx) in enumerate(splits, 1):\n",
    "    print(f\"  Split {i}: Train [{train_idx[0]:3d}:{train_idx[-1]:3d}]  Test [{test_idx[0]:3d}:{test_idx[-1]:3d}]\")\n",
    "\n",
    "# Visualizar split temporal\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(splits):\n",
    "    # Train\n",
    "    ax.barh(i, len(train_idx), left=train_idx[0], height=0.8, \n",
    "            color='#00d4ff', alpha=0.6, label='Train' if i == 0 else '')\n",
    "    # Test\n",
    "    ax.barh(i, len(test_idx), left=test_idx[0], height=0.8, \n",
    "            color='#ff4444', alpha=0.8, label='Test' if i == 0 else '')\n",
    "\n",
    "ax.set_yticks(range(len(splits)))\n",
    "ax.set_yticklabels([f'Split {i+1}' for i in range(len(splits))])\n",
    "ax.set_xlabel('√çndice de Amostra (Temporal)')\n",
    "ax.set_title('Walk-Forward Validation - Splits Temporais', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modelos a Testar\n",
    "\n",
    "### 7.1 Baseline: Modelo Ing√™nuo (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_naive_persistence(y_test, current_price):\n",
    "    \"\"\"\n",
    "    Baseline: assume que o pre√ßo permanece constante\n",
    "    Previs√£o = pre√ßo atual (retorno = 0)\n",
    "    \"\"\"\n",
    "    return np.zeros_like(y_test)\n",
    "\n",
    "def modelo_naive_random_walk(y_test, historical_returns):\n",
    "    \"\"\"\n",
    "    Baseline: assume random walk (previs√£o = m√©dia hist√≥rica)\n",
    "    \"\"\"\n",
    "    mean_return = np.mean(historical_returns)\n",
    "    return np.full_like(y_test, mean_return)\n",
    "\n",
    "print(\"‚úÖ Modelos baseline configurados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Modelo 1: LSTM Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_lstm(input_shape, forecast_horizon, units=50):\n",
    "    \"\"\"\n",
    "    LSTM simples para previs√£o de s√©ries temporais\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(units, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units // 2, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon)  # Output: 5 retornos futuros\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Modelo LSTM configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Modelo 2: GRU (mais leve que LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_gru(input_shape, forecast_horizon, units=50):\n",
    "    \"\"\"\n",
    "    GRU: mais eficiente que LSTM, bom para poucos dados\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        GRU(units, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        GRU(units // 2, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Modelo GRU configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Modelo 3: Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_bilstm(input_shape, forecast_horizon, units=50):\n",
    "    \"\"\"\n",
    "    Bi-LSTM: processa sequ√™ncia em ambas dire√ß√µes\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(units, return_sequences=True), input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Bidirectional(LSTM(units // 2, return_sequences=False)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Modelo Bi-LSTM configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Modelo 4: Temporal CNN (1D Convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_cnn_temporal(input_shape, forecast_horizon):\n",
    "    \"\"\"\n",
    "    CNN 1D para s√©ries temporais: captura padr√µes locais\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Modelo CNN Temporal configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Modelo 5: H√≠brido CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_modelo_hibrido_cnn_lstm(input_shape, forecast_horizon):\n",
    "    \"\"\"\n",
    "    H√≠brido: CNN para extra√ß√£o de features + LSTM para depend√™ncia temporal\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(forecast_horizon)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Modelo H√≠brido CNN+LSTM configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Treinamento e Valida√ß√£o com Walk-Forward\n",
    "\n",
    "### 8.1 Fun√ß√£o de Avalia√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas de erro\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    rmse = np.sqrt(mean_squared_error(y_true.flatten(), y_pred.flatten()))\n",
    "    mape = mean_absolute_percentage_error(y_true.flatten(), y_pred.flatten()) * 100\n",
    "    \n",
    "    # Acur√°cia direcional: acertou a dire√ß√£o (alta/baixa)?\n",
    "    direction_true = np.sign(y_true)\n",
    "    direction_pred = np.sign(y_pred)\n",
    "    direction_accuracy = np.mean(direction_true == direction_pred) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape,\n",
    "        'DirectionAcc': direction_accuracy\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ M√©tricas configuradas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Treinar e Validar LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks para early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=0.00001,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"üöÄ Treinando LSTM com Walk-Forward Validation...\\n\")\n",
    "\n",
    "resultados_lstm = []\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(splits, 1):\n",
    "    print(f\"\\nüìä Split {i}/{len(splits)}\")\n",
    "    print(f\"   Train: {len(train_idx)} samples, Test: {len(test_idx)} samples\")\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Criar e treinar modelo\n",
    "    model = criar_modelo_lstm(\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        forecast_horizon=FORECAST_HORIZON,\n",
    "        units=50\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Prever\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    \n",
    "    # Avaliar\n",
    "    metricas = calcular_metricas(y_test, y_pred)\n",
    "    metricas['split'] = i\n",
    "    metricas['epochs_trained'] = len(history.history['loss'])\n",
    "    resultados_lstm.append(metricas)\n",
    "    \n",
    "    print(f\"   ‚úÖ MAE: {metricas['MAE']:.6f}\")\n",
    "    print(f\"   ‚úÖ RMSE: {metricas['RMSE']:.6f}\")\n",
    "    print(f\"   ‚úÖ MAPE: {metricas['MAPE']:.2f}%\")\n",
    "    print(f\"   ‚úÖ Direction Acc: {metricas['DirectionAcc']:.2f}%\")\n",
    "    print(f\"   ‚è±Ô∏è Epochs: {metricas['epochs_trained']}\")\n",
    "\n",
    "# Resultados agregados\n",
    "df_resultados_lstm = pd.DataFrame(resultados_lstm)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä RESULTADOS M√âDIOS - LSTM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"MAE m√©dio:           {df_resultados_lstm['MAE'].mean():.6f} ¬± {df_resultados_lstm['MAE'].std():.6f}\")\n",
    "print(f\"RMSE m√©dio:          {df_resultados_lstm['RMSE'].mean():.6f} ¬± {df_resultados_lstm['RMSE'].std():.6f}\")\n",
    "print(f\"MAPE m√©dio:          {df_resultados_lstm['MAPE'].mean():.2f}% ¬± {df_resultados_lstm['MAPE'].std():.2f}%\")\n",
    "print(f\"Direction Acc m√©dio: {df_resultados_lstm['DirectionAcc'].mean():.2f}% ¬± {df_resultados_lstm['DirectionAcc'].std():.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Comparar Todos os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Comparando TODOS os modelos...\\n\")\n",
    "\n",
    "modelos_config = {\n",
    "    'LSTM': criar_modelo_lstm,\n",
    "    'GRU': criar_modelo_gru,\n",
    "    'Bi-LSTM': criar_modelo_bilstm,\n",
    "    'CNN-1D': criar_modelo_cnn_temporal,\n",
    "    'CNN+LSTM': criar_modelo_hibrido_cnn_lstm\n",
    "}\n",
    "\n",
    "resultados_todos = {nome: [] for nome in modelos_config.keys()}\n",
    "\n",
    "for nome_modelo, criar_funcao in modelos_config.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä Modelo: {nome_modelo}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(splits, 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Criar modelo\n",
    "        model = criar_funcao(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            forecast_horizon=FORECAST_HORIZON\n",
    "        )\n",
    "        \n",
    "        # Treinar\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=16,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop, reduce_lr],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Prever\n",
    "        y_pred = model.predict(X_test, verbose=0)\n",
    "        \n",
    "        # Avaliar\n",
    "        metricas = calcular_metricas(y_test, y_pred)\n",
    "        metricas['split'] = i\n",
    "        resultados_todos[nome_modelo].append(metricas)\n",
    "        \n",
    "        print(f\"  Split {i}: MAE={metricas['MAE']:.6f}, DirAcc={metricas['DirectionAcc']:.1f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ Treinamento completo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Visualizar Compara√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar resultados\n",
    "comparacao = []\n",
    "for nome_modelo, resultados in resultados_todos.items():\n",
    "    df_temp = pd.DataFrame(resultados)\n",
    "    comparacao.append({\n",
    "        'Modelo': nome_modelo,\n",
    "        'MAE_mean': df_temp['MAE'].mean(),\n",
    "        'MAE_std': df_temp['MAE'].std(),\n",
    "        'RMSE_mean': df_temp['RMSE'].mean(),\n",
    "        'RMSE_std': df_temp['RMSE'].std(),\n",
    "        'MAPE_mean': df_temp['MAPE'].mean(),\n",
    "        'MAPE_std': df_temp['MAPE'].std(),\n",
    "        'DirAcc_mean': df_temp['DirectionAcc'].mean(),\n",
    "        'DirAcc_std': df_temp['DirectionAcc'].std()\n",
    "    })\n",
    "\n",
    "df_comparacao = pd.DataFrame(comparacao)\n",
    "\n",
    "print(\"\\nüìä COMPARA√á√ÉO DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "display(df_comparacao.round(4))\n",
    "\n",
    "# Gr√°fico de compara√ß√£o\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# MAE\n",
    "ax1.barh(df_comparacao['Modelo'], df_comparacao['MAE_mean'], xerr=df_comparacao['MAE_std'], color='#00d4ff', alpha=0.7)\n",
    "ax1.set_xlabel('MAE (Mean Absolute Error)')\n",
    "ax1.set_title('MAE por Modelo', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE\n",
    "ax2.barh(df_comparacao['Modelo'], df_comparacao['RMSE_mean'], xerr=df_comparacao['RMSE_std'], color='#ff4444', alpha=0.7)\n",
    "ax2.set_xlabel('RMSE (Root Mean Squared Error)')\n",
    "ax2.set_title('RMSE por Modelo', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAPE\n",
    "ax3.barh(df_comparacao['Modelo'], df_comparacao['MAPE_mean'], xerr=df_comparacao['MAPE_std'], color='orange', alpha=0.7)\n",
    "ax3.set_xlabel('MAPE (%)')\n",
    "ax3.set_title('MAPE por Modelo', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Direction Accuracy\n",
    "ax4.barh(df_comparacao['Modelo'], df_comparacao['DirAcc_mean'], xerr=df_comparacao['DirAcc_std'], color='green', alpha=0.7)\n",
    "ax4.set_xlabel('Direction Accuracy (%)')\n",
    "ax4.set_title('Acur√°cia Direcional por Modelo', fontweight='bold')\n",
    "ax4.axvline(50, color='red', linestyle='--', label='Random (50%)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quantifica√ß√£o de Incerteza\n",
    "\n",
    "### 9.1 Intervalos de Confian√ßa via Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_com_incerteza(model, X_test, n_iter=100):\n",
    "    \"\"\"\n",
    "    Monte Carlo Dropout: faz m√∫ltiplas previs√µes com dropout ativo\n",
    "    para estimar incerteza\n",
    "    \"\"\"\n",
    "    # Habilitar dropout durante infer√™ncia\n",
    "    previsoes = []\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        pred = model(X_test, training=True)  # training=True mant√©m dropout ativo\n",
    "        previsoes.append(pred.numpy())\n",
    "    \n",
    "    previsoes = np.array(previsoes)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    mean_pred = np.mean(previsoes, axis=0)\n",
    "    std_pred = np.std(previsoes, axis=0)\n",
    "    \n",
    "    # Intervalos de confian√ßa (95%)\n",
    "    lower_bound = np.percentile(previsoes, 2.5, axis=0)\n",
    "    upper_bound = np.percentile(previsoes, 97.5, axis=0)\n",
    "    \n",
    "    return mean_pred, std_pred, lower_bound, upper_bound\n",
    "\n",
    "print(\"‚úÖ Quantifica√ß√£o de incerteza configurada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclus√µes e Recomenda√ß√µes\n",
    "\n",
    "### 10.1 An√°lise de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã CONCLUS√ïES DO ESTUDO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîç OBSERVA√á√ïES:\")\n",
    "print(\"\\n1. M√âTRICAS REALISTAS\")\n",
    "print(\"   - MAE t√≠pico: 0.01-0.03 (1-3% de erro nos retornos)\")\n",
    "print(\"   - Direction Accuracy: 50-60% (pr√≥ximo ao random)\")\n",
    "print(\"   - Isso √© ESPERADO para s√©ries financeiras com poucos dados\")\n",
    "\n",
    "print(\"\\n2. COMPARA√á√ÉO DE MODELOS\")\n",
    "print(\"   - LSTM/GRU: Melhores para capturar depend√™ncias temporais\")\n",
    "print(\"   - CNN-1D: R√°pido, mas perde contexto temporal longo\")\n",
    "print(\"   - H√≠brido CNN+LSTM: Balanceado\")\n",
    "\n",
    "print(\"\\n3. LIMITA√á√ïES FUNDAMENTAIS\")\n",
    "print(\"   - Poucos dados (6 meses) limitam generaliza√ß√£o\")\n",
    "print(\"   - Mercado √© n√£o-estacion√°rio (padr√µes mudam)\")\n",
    "print(\"   - Eventos externos n√£o s√£o capturados (not√≠cias, pol√≠tica)\")\n",
    "print(\"   - Efici√™ncia de mercado: muita informa√ß√£o j√° est√° no pre√ßo\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° RECOMENDA√á√ïES PARA O APP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ IMPLEMENTAR:\")\n",
    "print(\"   1. Usar GRU ou LSTM (melhor para temporal)\")\n",
    "print(\"   2. Walk-forward validation (valida√ß√£o temporal rigorosa)\")\n",
    "print(\"   3. Intervalos de confian√ßa (Monte Carlo Dropout)\")\n",
    "print(\"   4. Confian√ßa realista: 40-60% em vez de 70-90%\")\n",
    "print(\"   5. Mostrar intervalo de previs√£o (n√£o apenas ponto √∫nico)\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è AVISOS AO USU√ÅRIO:\")\n",
    "print(\"   - 'Confian√ßa baixa/moderada √© normal para a√ß√µes'\")\n",
    "print(\"   - 'Previs√£o de 5 dias √© altamente incerta'\")\n",
    "print(\"   - 'Use como refer√™ncia, n√£o como decis√£o de investimento'\")\n",
    "print(\"   - 'Direction Accuracy de 55% √© marginalmente melhor que sorte (50%)'\")\n",
    "\n",
    "print(\"\\nüìä MELHORIAS FUTURAS:\")\n",
    "print(\"   1. Mais dados (1-2 anos m√≠nimo, idealmente 5-10 anos)\")\n",
    "print(\"   2. Features externas (sentimento de not√≠cias, volume institucional)\")\n",
    "print(\"   3. Ensemble com m√∫ltiplos horizontes de tempo\")\n",
    "print(\"   4. Ajuste din√¢mico de confian√ßa baseado em volatilidade recente\")\n",
    "print(\"   5. An√°lise de regimes de mercado (bull vs bear)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. C√≥digo Final Recomendado para o App\n",
    "\n",
    "### 11.1 Fun√ß√£o para substituir no app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\n\n",
    "üìù C√ìDIGO PARA SUBSTITUIR NO APP.PY:\n",
    "=====================================\n",
    "\n",
    "def gerar_previsao_acao_melhorada(dados_acao):\n",
    "    \\\"\\\"\\\"\\nPrevis√£o com modelo temporal (GRU) e incerteza quantificada\n",
    "    \\\"\\\"\\\"\\n    try:\n",
    "        historico = dados_acao.get('historico')\n",
    "        if historico is None or len(historico) < 60:\n",
    "            return None, None, None, None, \"Dados hist√≥ricos insuficientes\"\n",
    "        \n",
    "        # Preparar dados\n",
    "        df = adicionar_features_tecnicas(historico)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        if len(df) < 40:\n",
    "            return None, None, None, None, \"Dados insuficientes ap√≥s limpeza\"\n",
    "        \n",
    "        # Criar sequ√™ncias temporais\n",
    "        X, y, _, _, scaler = criar_sequencias_temporais(df, window_size=20, forecast_horizon=5)\n",
    "        \n",
    "        # Usar walk-forward: treinar com 80% mais antigos, testar no mais recente\n",
    "        split_point = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split_point], X[split_point:]\n",
    "        y_train, y_test = y[:split_point], y[split_point:]\n",
    "        \n",
    "        # Criar modelo GRU\n",
    "        model = criar_modelo_gru(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            forecast_horizon=5,\n",
    "            units=50\n",
    "        )\n",
    "        \n",
    "        # Treinar\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=16,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Prever com incerteza (Monte Carlo Dropout)\n",
    "        last_sequence = X[-1:]\n",
    "        mean_pred, std_pred, lower, upper = prever_com_incerteza(model, last_sequence, n_iter=100)\n",
    "        \n",
    "        # Converter retornos para pre√ßos\n",
    "        preco_atual = dados_acao['preco']\n",
    "        previsoes = []\n",
    "        lower_bounds = []\n",
    "        upper_bounds = []\n",
    "        \n",
    "        for i in range(5):\n",
    "            preco = preco_atual * (1 + mean_pred[0][i])\n",
    "            lower_b = preco_atual * (1 + lower[0][i])\n",
    "            upper_b = preco_atual * (1 + upper[0][i])\n",
    "            \n",
    "            previsoes.append(preco)\n",
    "            lower_bounds.append(lower_b)\n",
    "            upper_bounds.append(upper_b)\n",
    "        \n",
    "        # Calcular confian√ßa REALISTA (baseada em volatilidade das previs√µes)\n",
    "        volatilidade_previsao = np.mean(std_pred)\n",
    "        confianca = max(0.3, min(0.65, 1.0 - volatilidade_previsao * 10))  # 30-65%\n",
    "        \n",
    "        # Gerar datas\n",
    "        datas = []\n",
    "        data_atual = historico.index.max()\n",
    "        dias_adicionados = 0\n",
    "        while dias_adicionados < 5:\n",
    "            data_atual += timedelta(days=1)\n",
    "            if data_atual.weekday() < 5:\n",
    "                datas.append(data_atual)\n",
    "                dias_adicionados += 1\n",
    "        \n",
    "        resultado = {\n",
    "            'previsoes': np.array(previsoes),\n",
    "            'datas': datas,\n",
    "            'confianca': confianca,\n",
    "            'lower_bound': np.array(lower_bounds),\n",
    "            'upper_bound': np.array(upper_bounds),\n",
    "            'volatilidade': volatilidade_previsao\n",
    "        }\n",
    "        \n",
    "        return resultado, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, f\"Erro: {str(e)}\"\n",
    "\n",
    "=====================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Refer√™ncias e Estudos Adicionais\n",
    "\n",
    "### Papers Relevantes:\n",
    "1. **\"Financial Time Series Forecasting with Deep Learning\"** - Sezer et al. (2020)\n",
    "2. **\"LSTM for Stock Market Prediction\"** - Fischer & Krauss (2018)\n",
    "3. **\"Dropout as a Bayesian Approximation\"** - Gal & Ghahramani (2016)\n",
    "\n",
    "### Conceitos Importantes:\n",
    "- **Walk-Forward Validation**: Valida√ß√£o temporal rigorosa\n",
    "- **Monte Carlo Dropout**: Quantifica√ß√£o de incerteza epist√™mica\n",
    "- **Direction Accuracy**: M√©trica mais relevante que MAE para trading\n",
    "- **Efficient Market Hypothesis**: Limite te√≥rico da previsibilidade\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
